### Guiding Principles of Responsible AI

Transparency & Explainability → AI systems should be understandable, and their decisions explainable to users.

Fairness & Non-Discrimination → AI must avoid bias and treat all individuals fairly.

Accountability → Clear responsibility must be assigned for AI outcomes.

Privacy & Data Protection → Safeguard user data with strong security and privacy measures.

Human-Centered Design → AI should augment human decision-making, not replace or harm it.

Safety & Reliability → AI must be tested thoroughly to work reliably in different conditions.

Sustainability → AI development should consider environmental and social impact.

Continuous Monitoring & Improvement → Regularly evaluate AI systems for risks and unintended consequences.
### Fallbacks of AI

While AI has numerous benefits, it's essential to consider the potential fallbacks. Guiding principles of AI include:

Responsible AI: AI should be robust, careful, and lawful. It's essential to ensure that AI systems are transparent, explainable, and fair.

AI Ethics: AI should respect human ethics, including respect, no harm, transparency, and accountability.

Some pressing concerns when building AI applications include:

Prompt Injection: Attempts to cause harm or behave contrary to deployment experts.

Memorization Leaked Prompt: Not disclosing private data.