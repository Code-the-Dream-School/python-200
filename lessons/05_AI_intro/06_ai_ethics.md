### Guiding Principles of Responsible AI

Transparency & Explainability → AI systems should be understandable, and their decisions explainable to users.
https://www.ibm.com/think/topics/ai-transparency
https://www.ibm.com/think/topics/explainable-ai
Fairness & Non-Discrimination → AI must avoid bias and treat all individuals fairly.
https://www.blueprism.com/resources/blog/bias-fairness-ai/
https://datatron.com/real-life-examples-of-discriminating-artificial-intelligence/
https://www.nature.com/articles/s41599-023-02079-x

Accountability → Clear responsibility must be assigned for AI outcomes.
https://carnegiecouncil.org/explore-engage/key-terms/ai-accountability
https://www.credo.ai/glossary/accountability

Privacy & Data Protection → Safeguard user data with strong security and privacy measures.
https://www.ibm.com/think/insights/ai-privacy
https://hai.stanford.edu/news/privacy-ai-era-how-do-we-protect-our-personal-information

Human-Centered Design → AI should augment human decision-making, not replace or harm it.

Safety & Reliability → AI must be tested thoroughly to work reliably in different conditions.

Sustainability → AI development should consider environmental and social impact.

Continuous Monitoring & Improvement → Regularly evaluate AI systems for risks and unintended consequences.
### Fallbacks of AI

While AI has numerous benefits, it's essential to consider the potential fallbacks. Guiding principles of AI include:

Responsible AI: AI should be robust, careful, and lawful. It's essential to ensure that AI systems are transparent, explainable, and fair.

AI Ethics: AI should respect human ethics, including respect, no harm, transparency, and accountability.

Some pressing concerns when building AI applications include:

Prompt Injection: Attempts to cause harm or behave contrary to deployment experts.

Memorization Leaked Prompt: Not disclosing private data.


